#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
RAG ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ìƒì„±ëœ ë²¡í„° DBê°€ ì œëŒ€ë¡œ ì‘ë™í•˜ëŠ”ì§€ ê²€ì¦í•©ë‹ˆë‹¤.
"""

import os
import sys
from pathlib import Path
from typing import List, Dict, Any
import logging

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root / "backend" / "data_generator" / "vectorDB"))

from langchain_community.vectorstores import FAISS

# ì„ë² ë”© ëª¨ë¸ import
try:
    import boto3
    from langchain_aws import BedrockEmbeddings
    BEDROCK_AVAILABLE = True
except ImportError:
    BEDROCK_AVAILABLE = False

try:
    from langchain_google_genai import GoogleGenerativeAIEmbeddings
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False

try:
    from langchain_openai import OpenAIEmbeddings
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def initialize_embeddings(embedding_model: str = "bedrock"):
    """ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”"""
    embedding_model = embedding_model.lower()
    
    if embedding_model == "bedrock" or embedding_model == "titan":
        if not BEDROCK_AVAILABLE:
            raise ImportError(
                "AWS Bedrock ì„ë² ë”© ëª¨ë¸ì„ ì‚¬ìš©í•˜ë ¤ë©´ 'boto3'ì™€ 'langchain-aws' íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤."
            )
        
        access_key_id = os.getenv("AWS_ACCESS_KEY_ID")
        secret_access_key = os.getenv("AWS_SECRET_ACCESS_KEY") or os.getenv("AWS_BEDROCK_API_KEY")
        region = os.getenv("AWS_DEFAULT_REGION", "ap-northeast-2")
        
        if not access_key_id or not secret_access_key:
            raise ValueError(
                "AWS Bedrock ìê²© ì¦ëª…ì´ í•„ìš”í•©ë‹ˆë‹¤. í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”."
            )
        
        bedrock_client = boto3.client(
            'bedrock-runtime',
            aws_access_key_id=access_key_id,
            aws_secret_access_key=secret_access_key,
            region_name=region
        )
        
        return BedrockEmbeddings(
            client=bedrock_client,
            model_id="amazon.titan-embed-text-v2:0"
        )
    
    elif embedding_model == "gemini":
        if not GEMINI_AVAILABLE:
            raise ImportError("Gemini ì„ë² ë”© ëª¨ë¸ íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        api_key = os.getenv("GOOGLE_API_KEY")
        if not api_key:
            raise ValueError("GOOGLE_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        return GoogleGenerativeAIEmbeddings(
            model="models/embedding-001",
            google_api_key=api_key
        )
    
    elif embedding_model == "openai":
        if not OPENAI_AVAILABLE:
            raise ImportError("OpenAI ì„ë² ë”© ëª¨ë¸ íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        return OpenAIEmbeddings(openai_api_key=api_key)
    
    else:
        raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì„ë² ë”© ëª¨ë¸: {embedding_model}")


def load_vector_db(db_path: Path, embeddings):
    """ë²¡í„° DB ë¡œë“œ"""
    if not db_path.exists():
        raise FileNotFoundError(f"ë²¡í„° DBë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {db_path}")
    
    logger.info(f"ë²¡í„° DB ë¡œë“œ ì¤‘: {db_path}")
    vector_store = FAISS.load_local(
        str(db_path),
        embeddings,
        allow_dangerous_deserialization=True
    )
    
    logger.info("ë²¡í„° DB ë¡œë“œ ì™„ë£Œ")
    return vector_store


def test_query(vector_store, query: str, k: int = 3) -> List[Dict[str, Any]]:
    """ì§ˆë¬¸ì— ëŒ€í•œ ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰"""
    logger.info(f"\nì§ˆë¬¸: {query}")
    logger.info("-" * 80)
    
    # ìœ ì‚¬ë„ ê²€ìƒ‰
    docs = vector_store.similarity_search_with_score(query, k=k)
    
    results = []
    for i, (doc, score) in enumerate(docs, 1):
        result = {
            "rank": i,
            "score": score,
            "content": doc.page_content[:200] + "..." if len(doc.page_content) > 200 else doc.page_content,
            "full_content": doc.page_content,
            "source_file": doc.metadata.get("file_name", "Unknown"),
            "metadata": doc.metadata
        }
        results.append(result)
        
        logger.info(f"\n[ê²°ê³¼ {i}] (ìœ ì‚¬ë„ ì ìˆ˜: {score:.4f})")
        logger.info(f"ì¶œì²˜: {result['source_file']}")
        logger.info(f"ë‚´ìš©: {result['content']}")
    
    return results


def run_tests():
    """RAG ë²¡í„° DB í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    
    print("=" * 80)
    print("RAG ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    
    # ê²½ë¡œ ì„¤ì •
    project_root = Path(__file__).parent.parent.parent.parent
    db_name = "law_db"
    db_path = project_root / "backend" / "data" / "RAG" / db_name
    
    # ê¸°ë³¸ ì„ë² ë”© ëª¨ë¸ (ë²¡í„° DB ìƒì„± ì‹œ ì‚¬ìš©í•œ ëª¨ë¸)
    embedding_model = os.getenv("TEST_EMBEDDING_MODEL", "bedrock")
    
    try:
        # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
        logger.info(f"ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”: {embedding_model}")
        embeddings = initialize_embeddings(embedding_model)
        
        # ë²¡í„° DB ë¡œë“œ
        vector_store = load_vector_db(db_path, embeddings)
        
        # ë²¡í„° DB ì •ë³´
        print(f"\nâœ… ë²¡í„° DB ë¡œë“œ ì„±ê³µ!")
        print(f"   ê²½ë¡œ: {db_path}")
        print(f"   ì„ë² ë”© ëª¨ë¸: {embedding_model}")
        
        # ìš”ì‹ì—… ê´€ë ¨ í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ë“¤ (ê°„ë‹¨í•œ ê²€ì¦ìš©ìœ¼ë¡œ ì§ˆë¬¸ ìˆ˜ ì¡°ì • ê°€ëŠ¥)
        # TEST_QUICK ëª¨ë“œì—ì„œëŠ” ì²« ë²ˆì§¸ ì§ˆë¬¸ë§Œ ì‹¤í–‰
        quick_mode = os.getenv("TEST_QUICK", "false").lower() == "true"
        
        test_questions = [
            "ì‹í’ˆ ìœ„ìƒë²•ì—ì„œ ìš”ì‹ì—…ì²´ê°€ ì¤€ìˆ˜í•´ì•¼ í•  ì£¼ìš” ì‚¬í•­ì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "ì‹í’ˆì ‘ê°ì—…ì†Œì˜ ì†Œí™”ê¸° ì„¤ì¹˜ ê¸°ì¤€ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
            "ì‹í’ˆ íŒë§¤ì—… í—ˆê°€ ì ˆì°¨ëŠ” ì–´ë–»ê²Œ ì§„í–‰ë˜ë‚˜ìš”?",
            "ìŒì‹ì ì—ì„œ ë¶€íŒ¨ë³€ì§ˆ ì‹í’ˆ íŒë§¤ ì‹œ ì²˜ë²Œ ê·œì •ì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "ë‹¤ì¤‘ì´ìš©ì—…ì†Œì—ì„œ ìš”ì‹ì—…ì„ ìš´ì˜í•  ë•Œ í•„ìš”í•œ ì•ˆì „ ì‹œì„¤ì€ ë¬´ì—‡ì¸ê°€ìš”?"
        ]
        
        if quick_mode:
            logger.info("âš¡ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ì²« ë²ˆì§¸ ì§ˆë¬¸ë§Œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
            test_questions = test_questions[:1]
        
        print("\n" + "=" * 80)
        print("í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ ì‹¤í–‰")
        print("=" * 80)
        
        all_results = []
        for i, question in enumerate(test_questions, 1):
            print(f"\n{'=' * 80}")
            print(f"í…ŒìŠ¤íŠ¸ {i}/{len(test_questions)}")
            print(f"{'=' * 80}")
            
            results = test_query(vector_store, question, k=3)
            all_results.append({
                "question": question,
                "results": results
            })
            
            print("\n" + "-" * 80)
        
        # í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½
        print("\n" + "=" * 80)
        print("í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
        print("=" * 80)
        
        total_queries = len(test_questions)
        successful_queries = sum(1 for r in all_results if r["results"])
        
        print(f"\nâœ… ì „ì²´ í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ ìˆ˜: {total_queries}")
        print(f"âœ… ì„±ê³µí•œ ê²€ìƒ‰ ìˆ˜: {successful_queries}")
        print(f"âœ… ì„±ê³µë¥ : {(successful_queries/total_queries)*100:.1f}%")
        
        # ê° ì§ˆë¬¸ë³„ ìµœê³  ì ìˆ˜ í‘œì‹œ
        print("\nğŸ“Š ì§ˆë¬¸ë³„ ìµœê³  ìœ ì‚¬ë„ ì ìˆ˜:")
        for i, result in enumerate(all_results, 1):
            if result["results"]:
                best_score = min(r["score"] for r in result["results"])  # ê±°ë¦¬ì´ë¯€ë¡œ ì‘ì„ìˆ˜ë¡ ì¢‹ìŒ
                print(f"   ì§ˆë¬¸ {i}: {best_score:.4f}")
            else:
                print(f"   ì§ˆë¬¸ {i}: ê²°ê³¼ ì—†ìŒ")
        
        # ì¶œì²˜ íŒŒì¼ í†µê³„
        all_sources = []
        for result in all_results:
            for r in result["results"]:
                all_sources.append(r["source_file"])
        
        from collections import Counter
        source_counts = Counter(all_sources)
        
        print("\nğŸ“ ê²€ìƒ‰ ê²°ê³¼ì— í¬í•¨ëœ ë¬¸ì„œ:")
        for source, count in source_counts.most_common():
            print(f"   - {source}: {count}íšŒ")
        
        print("\n" + "=" * 80)
        print("âœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print("=" * 80)
        
        return True
        
    except FileNotFoundError as e:
        logger.error(f"âŒ íŒŒì¼ ì˜¤ë¥˜: {e}")
        print("\ní•´ê²° ë°©ë²•:")
        print("  1. ë²¡í„° DBê°€ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”")
        print("  2. DB ê²½ë¡œê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ì„¸ìš”")
        return False
        
    except ValueError as e:
        logger.error(f"âŒ ì„¤ì • ì˜¤ë¥˜: {e}")
        print("\ní•´ê²° ë°©ë²•:")
        if "ìê²© ì¦ëª…" in str(e) or "API í‚¤" in str(e):
            if embedding_model == "bedrock":
                print("  - í™˜ê²½ ë³€ìˆ˜ ì„¤ì •:")
                print("    export AWS_ACCESS_KEY_ID='your-key'")
                print("    export AWS_BEDROCK_API_KEY='your-secret'")
                print("    export AWS_DEFAULT_REGION='ap-northeast-2'")
        return False
        
    except ImportError as e:
        logger.error(f"âŒ íŒ¨í‚¤ì§€ ì˜¤ë¥˜: {e}")
        print("\ní•´ê²° ë°©ë²•:")
        print("  - í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜: pip install -r requirements.txt")
        return False
        
    except Exception as e:
        logger.error(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}", exc_info=True)
        return False


if __name__ == "__main__":
    success = run_tests()
    sys.exit(0 if success else 1)

